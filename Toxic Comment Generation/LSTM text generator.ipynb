{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/train.csv\")\n",
    "X_toxic = df[(df['toxic'] == 1)]['comment_text']\n",
    "\n",
    "text = ''.join(X_toxic)\n",
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x93', '\\x94', '\\xa0', 'Â¢', 'Â£', 'Â¤', 'Â¦', 'Â§', 'Â¨', 'Â©', '\\xad', 'Â®', 'Â¯', 'Â°', 'Â±', 'Â²', 'Â´', 'Â·', 'Â¸', 'Â½', 'Â¿', 'ÃŸ', 'Ã ', 'Ã¡', 'Ã¤', 'Ã¥', 'Ã¦', 'Ã§', 'Ã¨', 'Ã©', 'Ãª', 'Ã­', 'Ã¯', 'Ã±', 'Ã³', 'Ã¶', 'Ã¹', 'Ãº', 'Ã¼', 'Ã¾', 'Ä…', 'Ä‡', 'Ä‘', 'Ä—', 'Ä›', 'Ä£', 'Ä¥', 'Ä§', 'Ä±', 'Å„', 'Å†', 'Å', 'Å“', 'Å›', 'ÅŸ', 'Å¡', 'Å£', 'Å©', 'Åµ', 'Å·', 'Å¼', 'Æ’', 'Ç”', 'È³', 'Ì‡', 'Î¬', 'Î¯', 'Î±', 'Î³', 'Î´', 'Îµ', 'Î·', 'Î¸', 'Î¹', 'Îº', 'Î»', 'Î¼', 'Î½', 'Î¿', 'Ï€', 'Ï', 'Ï‚', 'Ïƒ', 'Ï„', 'Ï…', 'Ï†', 'Ï‰', 'ÏŒ', 'Ï', 'Ï', 'Ğ°', 'Ğ±', 'Ğ²', 'Ğ³', 'Ğ´', 'Ğµ', 'Ğ¶', 'Ğ¸', 'Ğ¹', 'Ğº', 'Ğ»', 'Ğ¼', 'Ğ½', 'Ğ¾', 'Ğ¿', 'Ñ€', 'Ñ', 'Ñ‚', 'Ñƒ', 'Ñ…', 'Ñ†', 'Ñ‡', 'Ñ‰', 'ÑŠ', 'Ñ‹', 'ÑŒ', 'Ñ', 'Ñ™', 'Ö¼', '×', '×‘', '×•', '×™', '×›', '×œ', '×', 'Ø§', 'Øª', 'Ø³', 'Ø·', 'Ø¹', 'Ù', 'Ùƒ', 'Ù„', 'Ù…', 'Ù†', 'Ùˆ', 'ÙŠ', 'Ú†', 'Úœ', 'Ú¬', 'Ú°', 'Úµ', '\\u06dd', 'Û', 'Û¬', 'Ûµ', 'Û¸', 'Û»', 'Û¾', 'İ“', 'İ—', 'İœ', 'İŸ', 'İ¡', 'İ£', 'İ­', 'à¶š', 'à¶­', 'à¶³', 'à¶»', 'à·€', 'à·Š', 'à·”', 'á›', 'áµ½', 'á¸Ÿ', 'á¸»', 'á¹ƒ', 'á¹—', 'á¹£', 'á¹¯', '\\u200e', 'â€“', 'â€”', 'â€˜', 'â€™', 'â€œ', 'â€', 'â€', 'â€ ', 'â€¢', 'â€¦', '\\u2060', 'â‚¡', 'â‚¨', 'â‚©', 'â‚ª', 'â‚¬', 'â‚­', 'â‚³', 'â‚µ', 'â„–', 'â„¢', 'â„³', 'â…', 'â†', 'â†‘', 'â†’', 'â†”', 'â†¨', 'â‡’', 'â‡”', 'âˆ‚', 'âˆ†', 'âˆ‡', 'âˆ’', 'âˆš', 'âˆ', 'âˆ«', 'â‰ˆ', 'â‰ ', 'â‰¤', 'âŠ•', 'â”€', 'â•Ÿ', 'â•¢', 'â•¦', 'â–º', 'â—„', 'â˜…', 'â˜', 'â˜', 'â˜¥', 'â˜­', 'â˜º', 'â˜»', 'â˜¼', 'â™ ', 'â™£', 'â™¥', 'â™¦', 'â™ª', 'â™«', 'âœ„', 'âœ‰', 'âœ‹', 'âœ', 'âœ', 'âœ½', 'â', 'â', 'â¨', 'âŸ²', 'ãƒ„', 'å¦ˆ', 'å­¦', 'å½±', 'æƒ‘', 'æ­¦', 'æ°¸', 'çƒ‚', 'çš„', 'çµ¡', 'è€…', 'è‡­', 'è¦‹', 'è¨£', 'è¿·', 'é€£', '\\ufeff', 'ï¼', 'ï½', 'ï½ƒ', 'ï½‹', 'ï½Œ', 'ï½', 'ï½', 'ï½', 'ï½”', 'ï½—', 'ğŸ¼', 'ğŸ‘', 'ğŸ’©', 'ğŸ˜‚', 'ğŸ˜„', 'ğŸ˜Š']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  4515494\n",
      "Total Vocab:  347\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "n_chars = len(text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  4515394\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    sequence_in = text[i:i+ seq_length]\n",
    "    sequence_out = text[i + seq_length]\n",
    "    X.append([char_to_idx[char] for char in sequence_in])\n",
    "    y.append(char_to_idx[sequence_out])\n",
    "    \n",
    "n_patterns = len(X)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(X, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4515394/4515394 [==============================] - 13165s 3ms/step - loss: 2.4030\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.40299, saving model to weights-improvement-01-2.4030-bigger.hdf5\n",
      "Epoch 2/10\n",
      "4515394/4515394 [==============================] - 13218s 3ms/step - loss: 2.3467\n",
      "\n",
      "Epoch 00002: loss improved from 2.40299 to 2.34672, saving model to weights-improvement-02-2.3467-bigger.hdf5\n",
      "Epoch 3/10\n",
      "4515394/4515394 [==============================] - 13109s 3ms/step - loss: 2.5975\n",
      "\n",
      "Epoch 00003: loss did not improve from 2.34672\n",
      "Epoch 4/10\n",
      " 101184/4515394 [..............................] - ETA: 3:34:50 - loss: 2.7606"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=10, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-02-2.3467-bigger.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig \n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = numpy.random.randint(0, len(X)-1)\n",
    "pattern = X[start]\n",
    "print(\"Seed:\")\n",
    "print(''.join(idx_to_char[value] for value in pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig pig "
     ]
    }
   ],
   "source": [
    "# generate characters\n",
    "for i in range(500):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = idx_to_char[index]\n",
    "    seq_in = [idx_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
